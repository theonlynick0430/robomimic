{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "import robomimic.utils.train_utils as TrainUtils\n",
    "import robomimic.utils.torch_utils as TorchUtils\n",
    "from bc_benchmark_algos.dataset.robomimic import RobomimicDataset\n",
    "from bc_benchmark_algos.rollout_env.robomimic import RobomimicRolloutEnv\n",
    "from robomimic.config import config_factory\n",
    "from robomimic.algo import algo_factory, RolloutPolicy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup config\n",
    "config_path = \"../config/bc_rnn.json\"\n",
    "dataset_path = \"../../datasets/test/square_ph.hdf5\"\n",
    "output_dir = \"output\"\n",
    "ext_cfg = json.load(open(config_path, 'r'))\n",
    "config = config_factory(ext_cfg[\"algo_name\"])\n",
    "with config.unlocked():\n",
    "    config.update(ext_cfg)\n",
    "config.train.data = dataset_path\n",
    "config.train.output_dir = output_dir\n",
    "config.train.frame_stack = 2\n",
    "config.train.seq_length = 1\n",
    "config.lock()\n",
    "\n",
    "ObsUtils.initialize_obs_utils_with_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test tensor utils\n",
    "x = {\"obs\": {\"agentview_image\": np.random.randn(84, 84, 3)}}\n",
    "x = TensorUtils.to_tensor(x)\n",
    "assert isinstance(x[\"obs\"][\"agentview_image\"], torch.Tensor) \n",
    "x = TensorUtils.to_batch(x)\n",
    "assert x[\"obs\"][\"agentview_image\"].shape == (1, 84, 84, 3)\n",
    "x = TensorUtils.to_sequence(x)\n",
    "assert x[\"obs\"][\"agentview_image\"].shape == (1, 1, 84, 84, 3)\n",
    "x = TensorUtils.repeat_seq(x=x, k=10)\n",
    "assert x[\"obs\"][\"agentview_image\"].shape == (1, 10, 84, 84, 3)\n",
    "x = TensorUtils.slice(x=x, dim=1, start=0, end=5)\n",
    "assert x[\"obs\"][\"agentview_image\"].shape == (1, 5, 84, 84, 3)\n",
    "y = TensorUtils.shift_seq(x=x, k=1)\n",
    "assert torch.equal(x[\"obs\"][\"agentview_image\"][:, 0, :], y[\"obs\"][\"agentview_image\"][:, 1, :])\n",
    "y = TensorUtils.shift_seq(x=x, k=-1)\n",
    "assert torch.equal(x[\"obs\"][\"agentview_image\"], y[\"obs\"][\"agentview_image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validset\n",
    "dataset_path = \"../../datasets/test/square_ph.hdf5\"\n",
    "validset = RobomimicDataset.dataset_factory(\n",
    "    config=config,\n",
    "    obs_group_to_keys=ObsUtils.OBS_GROUP_TO_KEYS, \n",
    "    filter_by_attribute=\"valid\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rollout env\n",
    "_, _, video_dir = TrainUtils.get_exp_dir(config)\n",
    "rollout_env = RobomimicRolloutEnv(config=config, validset=validset)\n",
    "print(video_dir)\n",
    "print(rollout_env.env_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test inputs_from_initial_obs\n",
    "demo_id = validset.demos[0]\n",
    "initial_state = dict(states=validset.hdf5_file[f\"data/{demo_id}/states\"][0])\n",
    "initial_state[\"model\"] = validset.hdf5_file[f\"data/{demo_id}\"].attrs[\"model_file\"]\n",
    "rollout_env.env.reset()\n",
    "obs = rollout_env.env.reset_to(initial_state)\n",
    "inputs = rollout_env.inputs_from_initial_obs(obs=obs, demo_id=demo_id)\n",
    "assert inputs[\"goal\"][\"agentview_image\"].shape == (1, config.train.frame_stack+1, 84, 84, 3)\n",
    "assert np.all(np.equal(inputs[\"goal\"][\"agentview_image\"][0, 0, :], inputs[\"goal\"][\"agentview_image\"][0, 1, :]))\n",
    "assert np.all(np.equal(inputs[\"goal\"][\"agentview_image\"][0, 1, :], inputs[\"goal\"][\"agentview_image\"][0, 2, :]))\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "axs[0, 0].imshow(inputs[\"goal\"][\"agentview_image\"][0, 0, :])\n",
    "axs[0, 1].imshow(inputs[\"goal\"][\"agentview_image\"][0, 1, :])\n",
    "axs[0, 2].imshow(inputs[\"goal\"][\"agentview_image\"][0, 2, :])\n",
    "axs[1, 0].imshow(inputs[\"obs\"][\"agentview_image\"][0, 0, :])\n",
    "axs[1, 1].imshow(inputs[\"obs\"][\"agentview_image\"][0, 1, :])\n",
    "axs[1, 2].imshow(inputs[\"obs\"][\"agentview_image\"][0, 2, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test inputs_from_new_obs\n",
    "inputs = rollout_env.inputs_from_new_obs(x=inputs, obs=obs, demo_id=demo_id, t=10)\n",
    "assert inputs[\"obs\"][\"agentview_image\"].shape == (1, config.train.frame_stack+1, 84, 84, 3)\n",
    "assert np.any(np.not_equal(inputs[\"goal\"][\"agentview_image\"][0, 0, :], inputs[\"goal\"][\"agentview_image\"][0, 1, :]))\n",
    "assert np.any(np.not_equal(inputs[\"goal\"][\"agentview_image\"][0, 1, :], inputs[\"goal\"][\"agentview_image\"][0, 2, :]))\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "axs[0, 0].imshow(inputs[\"goal\"][\"agentview_image\"][0, 0, :])\n",
    "axs[0, 1].imshow(inputs[\"goal\"][\"agentview_image\"][0, 1, :])\n",
    "axs[0, 2].imshow(inputs[\"goal\"][\"agentview_image\"][0, 2, :])\n",
    "axs[1, 0].imshow(inputs[\"obs\"][\"agentview_image\"][0, 0, :])\n",
    "axs[1, 1].imshow(inputs[\"obs\"][\"agentview_image\"][0, 1, :])\n",
    "axs[1, 2].imshow(inputs[\"obs\"][\"agentview_image\"][0, 2, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "device = TorchUtils.get_torch_device(try_to_use_cuda=config.train.cuda)\n",
    "ac_dim = config.train.ac_dim\n",
    "model = algo_factory(\n",
    "    algo_name=config.algo_name,\n",
    "    config=config,\n",
    "    obs_key_shapes=ObsUtils.OBS_SHAPES,\n",
    "    ac_dim=ac_dim,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full rollout\n",
    "rollout_model = RolloutPolicy(policy=model)\n",
    "rollout_env.rollout_with_stats(\n",
    "    policy=rollout_model,\n",
    "    demo_id=validset.demos[0],\n",
    "    video_dir=video_dir\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
